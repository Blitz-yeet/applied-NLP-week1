{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2afd36",
   "metadata": {},
   "source": [
    "# 4) Gender in the Text: Pronouns & Nearby Verbs\n",
    "\n",
    "**Goal:** Compare relative frequency of pronouns and the verbs near them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7adbbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71b8216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pet Sematary chars: 812,353 | The Shining chars: 905,869\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_texts(\n",
    "    pet_path: str = \"../data/PetSemetary.txt\",\n",
    "    shining_path: str = \"../data/TheShining.txt\",\n",
    "):\n",
    "    \"\"\"Load Pet Sematary and The Shining texts from disk.\"\"\"\n",
    "    p1, p2 = Path(pet_path), Path(shining_path)\n",
    "\n",
    "    if not p1.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p1}\\n\"\n",
    "            \"→ Please place 'PetSemetary.txt' at this path or update load_texts(...).\"\n",
    "        )\n",
    "    if not p2.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p2}\\n\"\n",
    "            \"→ Please place 'TheShining.txt' at this path or update load_texts(...).\"\n",
    "        )\n",
    "\n",
    "    pet_text = p1.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    shining_text = p2.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    return pet_text, shining_text\n",
    "\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    \"\"\"Simple normalization for your own TXT files.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # normalize curly quotes to ASCII '\n",
    "    text = text.replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
    "    # normalize Windows line endings\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\")\n",
    "    # join hyphenated line breaks\n",
    "    text = re.sub(r\"-\\s*\\n\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Load and normalize\n",
    "pet_raw, shining_raw = load_texts()\n",
    "pet_norm     = normalize(pet_raw)\n",
    "shining_norm = normalize(shining_raw)\n",
    "\n",
    "print(f\"Pet Sematary chars: {len(pet_norm):,} | The Shining chars: {len(shining_norm):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244de30",
   "metadata": {},
   "source": [
    "### Helpers: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d13d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pet Sematary words   : 147,144 | The Shining words   : 162,085\n",
      "Pet Sematary sentences: 9,269 | The Shining sentences: 12,914\n"
     ]
    }
   ],
   "source": [
    "# ---------- 2. Tokenization ----------\n",
    "\n",
    "# keep apostrophes inside words (don't), but no apostrophe-only tokens\n",
    "WORD_RE = re.compile(r\"[A-Za-z]+(?:'[A-Za-z]+)*\")\n",
    "\n",
    "def words(text: str):\n",
    "    return WORD_RE.findall(text.lower())\n",
    "\n",
    "def sentences(text: str):\n",
    "    return [s.strip() for s in re.split(r\"(?<=[.!?])\\s+\", text) if s.strip()]\n",
    "\n",
    "pet_words     = words(pet_norm)\n",
    "shining_words = words(shining_norm)\n",
    "\n",
    "pet_sents     = sentences(pet_norm)\n",
    "shining_sents = sentences(shining_norm)\n",
    "\n",
    "print(f\"Pet Sematary words   : {len(pet_words):,} | The Shining words   : {len(shining_words):,}\")\n",
    "print(f\"Pet Sematary sentences: {len(pet_sents):,} | The Shining sentences: {len(shining_sents):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c3054",
   "metadata": {},
   "source": [
    "### Pronoun Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9daef9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pet Sematary pronouns: {'he': 3576, 'her': 1101, 'she': 1040, 'him': 864} total: 6581\n",
      "The Shining pronouns : {'he': 3616, 'him': 1104, 'her': 1111, 'she': 1208} total: 7039\n"
     ]
    }
   ],
   "source": [
    "# ---------- 3. Pronoun balance ----------\n",
    "\n",
    "def pronoun_counts(tokens):\n",
    "    target = {\"he\", \"she\", \"him\", \"her\"}\n",
    "    c = Counter(w for w in tokens if w in target)\n",
    "    total = sum(c.values())\n",
    "    return c, total\n",
    "\n",
    "pet_pron, pet_pron_tot = pronoun_counts(pet_words)\n",
    "sh_pron,  sh_pron_tot  = pronoun_counts(shining_words)\n",
    "\n",
    "print(\"Pet Sematary pronouns:\", dict(pet_pron), \"total:\", pet_pron_tot)\n",
    "print(\"The Shining pronouns :\", dict(sh_pron),  \"total:\", sh_pron_tot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd96ec",
   "metadata": {},
   "source": [
    "### Verbs Near Pronouns (very naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1179c210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pet Sematary – verbs near 'he'/'she':\n",
      "{'he': [('was', 486), ('said', 317), ('his', 206), ('thought', 143), ('as', 124), ('did', 105), ('felt', 99), ('louis', 87), ('saw', 87), ('looked', 66), ('supposed', 54), ('went', 51), ('this', 49), ('do', 44), ('knew', 40), ('turned', 39), ('asked', 34), ('remembered', 33), ('go', 32), ('going', 29)], 'she': [('said', 189), ('was', 164), ('thought', 29), ('as', 28), ('louis', 27), ('looked', 25), ('did', 21), ('asked', 15), ('is', 14), ('think', 14), ('his', 13), ('saw', 13), ('come', 13), ('going', 13), ('felt', 13), ('know', 12), ('smiled', 12), ('turned', 11), ('wanted', 11), ('this', 11)]}\n",
      "\n",
      "The Shining – verbs near 'he'/'she':\n",
      "{'he': [('was', 495), ('said', 243), ('his', 241), ('as', 125), ('looked', 94), ('thought', 87), ('did', 68), ('felt', 65), ('knew', 65), ('went', 54), ('saw', 50), ('turned', 49), ('see', 47), ('is', 36), ('think', 33), ('know', 33), ('asked', 32), ('come', 32), ('go', 31), ('wanted', 31)], 'she': [('was', 162), ('said', 113), ('as', 45), ('his', 35), ('thought', 33), ('looked', 31), ('asked', 27), ('felt', 24), ('turned', 23), ('did', 23), ('saw', 22), ('went', 19), ('came', 18), ('knew', 16), ('see', 15), ('know', 14), ('yes', 12), ('wondered', 11), ('smiled', 11), ('come', 10)]}\n"
     ]
    }
   ],
   "source": [
    "# ---------- 4. Verbs near 'he' / 'she' (very naive) ----------\n",
    "\n",
    "def verb_like(word: str) -> bool:\n",
    "    # crude heuristic: surface forms with verb-like endings or common base forms\n",
    "    return (\n",
    "        bool(re.match(r\".*(ed|ing|s)$\", word))\n",
    "        or word in {\n",
    "            \"say\", \"says\", \"said\",\n",
    "            \"go\", \"goes\", \"went\",\n",
    "            \"come\", \"comes\", \"came\",\n",
    "            \"think\", \"thinks\", \"thought\",\n",
    "            \"see\", \"sees\", \"saw\",\n",
    "            \"know\", \"knows\", \"knew\",\n",
    "            \"do\", \"does\", \"did\",\n",
    "            \"feel\", \"feels\", \"felt\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "def verbs_near_pronouns(tokens, window: int = 2):\n",
    "    verbs_for = {\"he\": [], \"she\": []}\n",
    "    for i, w in enumerate(tokens):\n",
    "        if w in (\"he\", \"she\"):\n",
    "            for j in range(max(0, i - window), min(len(tokens), i + window + 1)):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                if verb_like(tokens[j]):\n",
    "                    verbs_for[w].append(tokens[j])\n",
    "    # return top 20 per pronoun\n",
    "    return {k: Counter(v).most_common(20) for k, v in verbs_for.items()}\n",
    "\n",
    "pet_verbs_near = verbs_near_pronouns(pet_words)\n",
    "sh_verbs_near  = verbs_near_pronouns(shining_words)\n",
    "\n",
    "print(\"Pet Sematary – verbs near 'he'/'she':\")\n",
    "print(pet_verbs_near)\n",
    "print(\"\\nThe Shining – verbs near 'he'/'she':\")\n",
    "print(sh_verbs_near)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e818908",
   "metadata": {},
   "source": [
    "**Prompt:** How do these crude patterns line up with character agency and narrative voice? What errors do you notice, and how would POS (Part OF Speech) tagging improve this?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
